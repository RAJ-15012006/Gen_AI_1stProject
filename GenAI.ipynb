{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3Lqpftp7GwScTbujrT0sw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RAJ-15012006/Gen_AI_1stProject/blob/main/GenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_xcBT3b6spB"
      },
      "outputs": [],
      "source": [
        "# Hugging face, Install and use ollama, Pull a model and talk about langchain\n",
        "# hugging face is a repo for all this language models\n",
        "# how to use a existing hugging face model\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
        "model_name = \"deepset/roberta-base-squad2\""
      ],
      "metadata": {
        "id": "XBHSl_fdCUqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# will ask a question and it need to answer\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name) # loading a model that existed already, t loads a ready-to-use QA model so you don’t need to train it from scratch.\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name) # loading a model that existed already, AutoTokenizer → This is a universal tokenizer loader in transformers.\n",
        "# It figures out which tokenizer to use (BERT tokenizer, GPT tokenizer, etc.) based on the model."
      ],
      "metadata": {
        "id": "2gQaPH70Do4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = pipeline(\"question-answering\", model=model, tokenizer=tokenizer) # tokenizer break into words"
      ],
      "metadata": {
        "id": "qIrVl-v6H72Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\"2 cups (470 ml) of water\",\n",
        "\"2 2.46-ounce (70 g) packets of Maggi\",\n",
        "\"1 tablespoon (15 ml) of vegetable oil\",\n",
        "\"1 1/2 cups (75 g) of finely diced vegetables, such as carrots, cabbage, or onion\",\n",
        "\"1 tablespoon (8 g) of garlic, minced\",\n",
        "\"1 to 2 Thai green chilies, chopped\",\n",
        "\"2 tablespoons (39 g) of hot sauce, such as schezwan sauce or sriracha sauce\",\n",
        "\"1 teaspoon (4.9 ml) of white vinegar\",\n",
        "\"2 tablespoons (12 g) of spring onions, chopped\",\n",
        "\"Salt, to taste.\"]"
      ],
      "metadata": {
        "id": "7NywQB0zJoNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# whatever you give model to train ask questions related to that\n",
        "while True:\n",
        "  user_input = input(\"Ask a question, press q to exit\")\n",
        "  if user_input == \"q\":\n",
        "    break\n",
        "  input_to_model = {\"question\": user_input, \"context\":\" \".join(corpus)} # question: The user’s question.\n",
        "\n",
        "# context: The text passage from which the answer should be extracted.\n",
        "  print (\"Answer: \",  nlp(input_to_model)['answer']) # nlp is a Hugging Face pipeline for Question Answering"
      ],
      "metadata": {
        "id": "m1swlQhZOLCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A2KArHpaO1aw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}